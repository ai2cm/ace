full_field: &FULL_FIELD

  loss: 'l2'
  lr: 1E-3
  scheduler: 'CosineAnnealingLR' # 'ReduceLROnPlateau'
  scheduler_T_max: 150
  lr_warmup_steps: 0
  weight_decay: 0.0 # 0.1

  # wireup stuff
  wireup_info: 'mpi'
  wireup_store: 'tcp'  

  train_data_path: '/train'
  valid_data_path: '/test'
  exp_dir: '/runs'

  num_data_workers: 4
  dt: 1 # how many timesteps ahead the model will predict
  n_history: 0 #how many previous timesteps to consider
  prediction_type: 'iterative'
  prediction_length: 35 #applicable only if prediction_type == 'iterative'
  n_initial_conditions: 5 #applicable only if prediction_type == 'iterative'
  valid_autoreg_steps: 20 # number of autoregressive steps for validation
  
  ics_type: 'specify_number'
  save_raw_forecasts: !!bool True
  save_channel: !!bool False
  masked_acc: !!bool False
  maskpath: None
  perturb: !!bool False
  add_noise: !!bool False
  noise_std: 0.
 
  add_grid: !!bool False
  N_grid_channels: 0
  gridtype: 'sinusoidal' #options 'sinusoidal' or 'linear'
  roll: !!bool False
  
  max_epochs: 150
  batch_size: 32
  nettype: 'afno2'
  patch_size: 8
  num_blocks: 8
  embed_dim: 768
  normalization_layer: 'instance_norm'
  skip_fno: 'linear' # 'linear', 'identity' or None
  nested_skip_fno: !!bool True # whether to nest the inner skip connection or have it be sequential, inside the AFNO block
  verbose: True

  #fno hyperparams
  width: 56
  modes: 32

  #options default, residual
  target: 'default' 

  in_channels: [0,1]
  out_channels: [0,1] #must be same as in_channels if prediction_type == 'iterative'
  normalization: 'zscore' #options zscore or minmax

  min_path: '/stats/mins.npy'
  max_path: '/stats/maxs.npy'
  time_means_path:   '/stats/time_means.npy'
  global_means_path: '/stats/global_means.npy'
  global_stds_path:  '/stats/global_stds.npy' 

  orography: !!bool False
  orography_path: None

  finetune: !!bool False

  log_to_screen: !!bool True
  log_to_wandb: !!bool True
  save_checkpoint: !!bool True

  enable_nhwc: !!bool False
  optimizer_type: 'FusedAdam'
  optimizer_beta1: 0.9
  optimizer_beta2: 0.999
  optimizer_max_grad_norm: 1.0 
  crop_size_x: None
  crop_size_y: None

  two_step_training: !!bool False
  plot_animations: !!bool False

  # Weights and biases configuration
  wandb_name: None # If None, config will be used but you can override it here
  wandb_group: None # If None, will be 'era5_wind' + config, but you can override it here
  wandb_project: "develop"
  wandb_entity: "flowgan" # but your username here
  wandb_api_key: "9d8e9a65d32861cce6a51e214fb94e02b0f8b10a"

afno_20ch: &AFNO_20CH
  <<: *FULL_FIELD
  lr: 5E-4
  batch_size: 64
  max_epochs: 150
  in_channels: [0, 1 ,2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
  out_channels: [0, 1 ,2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
  orography: !!bool False
  orography_path: None 

afno_26ch: &AFNO_26CH
  <<: *AFNO_20CH
  lr: 5E-4
  batch_size: 64
  max_epochs: 150
  in_channels: [0, 1 ,2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]
  out_channels: [0, 1 ,2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]

afno_26ch_v:
  <<: *AFNO_26CH
  nettype: 'vit'
  patch_size: 16
  n_head: 8

afno_26ch_v_finetune: &AFNO_26CH_V_F
  <<: *AFNO_26CH
  lr: 1E-4
  batch_size: 64
  max_epochs: 50
  nettype: 'vit'
  patch_size: 16
  n_head: 8
  scheduler_T_max: 50
  finetune: !!bool True
  pretrained_checkpoint_path: '/runs/afno_26ch_v/ngpu32_mp1_sp1/training_checkpoints/best_ckpt_mp0.tar'

afno_26ch_v_finetune_n_02:
  <<: *AFNO_26CH_V_F
  add_noise: !!bool True
  noise_std: 0.2

afno_26ch_v_finetune_n_01:
  <<: *AFNO_26CH_V_F
  add_noise: !!bool True
  noise_std: 0.1

afno_26ch_v_finetune_n_03:
  <<: *AFNO_26CH_V_F
  add_noise: !!bool True
  noise_std: 0.3

afno_20ch_finetune:
  <<: *AFNO_20CH
  lr: 1E-4
  batch_size: 64
  max_epochs: 50
  finetune: !!bool True
  #pretrained_checkpoint_path: /checkpoints/best_ckpt_mp{mp_rank}.tar
  #ics_type: 'datetime'
  #date_strings: ["2018-10-08 00:00:00"] # hc michael
  #perturb: !!bool False
  #train_data_path: '/pscratch/sd/s/shas1693/data/era5/train'
  #valid_data_path: '/pscratch/sd/s/shas1693/data/era5/out_of_sample'
  #min_path:        '/pscratch/sd/s/shas1693/data/era5/mins.npy'
  #max_path:        '/pscratch/sd/s/shas1693/data/era5/maxs.npy'
  #time_means_path:   '/pscratch/sd/s/shas1693/data/era5/time_means.npy'
  #global_means_path: '/pscratch/sd/s/shas1693/data/era5/global_means.npy'
  #global_stds_path:  '/pscratch/sd/s/shas1693/data/era5/global_stds.npy'
  
afno_26_ch_inference:
  <<: *AFNO_20CH
  in_channels: [0, 1 ,2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]
  out_channels: [0, 1 ,2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]
  nettype: 'afno'
  inf_data_path: '/out_of_sample/'
    
afno_26ch_finetune:
  <<: *AFNO_20CH
  lr: 1E-4
  batch_size: 64
  max_epochs: 50
  scheduler_T_max: 50
  finetune: !!bool True
  pretrained_checkpoint_path: '/runs/afno_26ch/ngpu32_mp1_sp1/training_checkpoints/best_ckpt_mp0.tar'

